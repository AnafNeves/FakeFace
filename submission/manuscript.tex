% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  man,floatsintext]{apa6}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\centering\begin{threeparttable}}
%   {\end{threeparttable}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\centering\begin{ThreePartTable}}{\end{ThreePartTable}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% Overwrite redefinition of paragraph and subparagraph by the default LaTeX template
% See https://github.com/crsh/papaja/issues/292
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\itshape\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

% \usepackage{etoolbox}
\makeatletter
\patchcmd{\HyOrg@maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\HyOrg@maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother

\usepackage{xpatch}
\makeatletter
\xapptocmd\appendix
  {\xapptocmd\section
    {\addcontentsline{toc}{section}{\appendixname\ifoneappendix\else~\theappendix\fi\\: #1}}
    {}{\InnerPatchFailed}%
  }
{}{\PatchFailed}
\keywords{visual illusions, illusion game, Pyllusion, personality, general factor\newline\indent Word count: 5114}
\usepackage{lineno}

\linenumbers
\usepackage{csquotes}
\usepackage[titles]{tocloft}
\cftpagenumbersoff{figure}
\renewcommand{\cftfigpresnum}{\itshape\figurename\enspace}
\renewcommand{\cftfigaftersnum}{.\space}
\setlength{\cftfigindent}{0pt}
\setlength{\cftafterloftitleskip}{0pt}
\settowidth{\cftfignumwidth}{Figure 10.\qquad}
\usepackage[labelfont=bf, font={scriptsize, color=gray}]{caption}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Too Beautiful to be Fake: Attractive Faces are Less Likely to be Judged as Artificially Generated},
  pdfauthor={Dominique Makowski1, An Shu Te1, Stephanie Kirk1, Ngoi Zi Liang1, \& S.H. Annabel Chen1, 2, 3, 4},
  pdflang={en-EN},
  pdfkeywords={visual illusions, illusion game, Pyllusion, personality, general factor},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{\textbf{Too Beautiful to be Fake: Attractive Faces are Less Likely to be Judged as Artificially Generated}}
\author{Dominique Makowski\textsuperscript{1}, An Shu Te\textsuperscript{1}, Stephanie Kirk\textsuperscript{1}, Ngoi Zi Liang\textsuperscript{1}, \& S.H. Annabel Chen\textsuperscript{1, 2, 3, 4}}
\date{}


\shorttitle{Illusion Game Validation}

\authornote{

Correspondence concerning this article should be addressed to Dominique Makowski, HSS 04-18, 48 Nanyang Avenue, Singapore (\href{mailto:dom.makowski@gmail.com}{\nolinkurl{dom.makowski@gmail.com}}).

The authors made the following contributions. Dominique Makowski: Conceptualization, Data curation, Formal Analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Supervision, Validation, Visualization, Writing -- original draft; An Shu Te: Project administration, Resources, Investigation, Writing -- original draft; Stephanie Kirk: Project administration, Resources, Writing -- original draft; Ngoi Zi Liang: Project administration, Resources, Writing -- review \& editing; S.H. Annabel Chen: Project administration, Supervision, Writing -- review \& editing.

Correspondence concerning this article should be addressed to Dominique Makowski, HSS 04-18, 48 Nanyang Avenue, Singapore. E-mail: \href{mailto:dom.makowski@gmail.com}{\nolinkurl{dom.makowski@gmail.com}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} School of Social Sciences, Nanyang Technological University, Singapore\\\textsuperscript{2} LKC Medicine, Nanyang Technological University, Singapore\\\textsuperscript{3} National Institute of Education, Singapore\\\textsuperscript{4} Centre for Research and Development in Learning, Nanyang Technological University, Singapore}

\abstract{%
Abstract abstract abstract.
}



\begin{document}
\maketitle

For the first time in the history of humanity, technology has enabled the creation of near-perfect simulations indistinguishable from reality. These artificial yet realistic constructs permeate all areas of life through immersive works of fiction, deep fakes (real-like images and videos generated by deep learning algorithms), virtual and augmented reality (VR and AR), artificial beings (artificial intelligence ``bots'' with or without a physical form), fake news and skewed narratives, of which ground truth is often hard to access (Nightingale \& Farid, 2022). Such progress not only carries important consequences for the technological and entertainment sectors, but also for security and politics, for instance if used for propaganda and disinformation, recruitment into malevolent organizations, or religious indoctrination (Pantserev, 2020). This issue is central to what has been coined the ``post-truth era'' (Lewandowsky et al., 2017), in which the distinction (and lack thereof) between authentic and simulated objects will play a critical role.

While not all simulations have achieved perfect realism (e.g., Computer Generated Images - CGI in movies often lack certain key details that makes them visually distinct from real images, McDonnell \& Breidt, 2010), it is fair to assume that these technical limitations will become negligible in the near future, in particular in the field of faces generation and replacement (Moshel et al., 2022; Nightingale \& Farid, 2022; Tucciarelli et al., 2020). This fact, however, leads to a new issue: if real and fake stimuli cannot be distinguished based on their objective characteristics, how can we make judgments regarding their nature?

Literature shows that the context surrounding a stimulus often plays an important role in the assessment of its reality (Makowski, 2018; a process henceforth referred to as \emph{simulation monitoring}, Makowski, Sperduti, et al., 2019). With the extensive search and processing of cues within ambiguous stimuli being an increasingly complex and cognitively effortful strategy (Michael \& Sanson, 2021; Susmann et al., 2021), people tend to draw on peripheral contextual cues (\textbf{Figure 1}), such as the source of the stimulus, and its credibility, authority and expertise, to help facilitate their evaluation {[}petty1986elaboration; Susmann et al. (2021); Michael and Sanson (2021){]}. However, the atomization and decontextualization of information allowed by online social media (where text snippets or video excerpts are mass-shared with little context) can render this task difficult {[}\emph{REF}{]}. In the absence of contextual information, what drives our beliefs of reality?

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/Figure1} \caption{The decision to believe that an ambiguous stimulus (of any form, e.g., images, text, videos, environments, ...) is real or fake depends of individual characteristics (e.g., personality and cognitive styles), stimulus-related features (context, emotionality), and their interaction, which can manifest for instance in our bodily reaction.}\label{fig:unnamed-chunk-2}
\end{figure}

Moreover, evidence from research indicates that inter-individual characteristics also play a crucial role in the formation of beliefs of reality, with factors such as cognitive style, prior beliefs, and personality traits significantly impacting simulation monitoring (Bryanov \& Vziatysheva, 2021; Ecker et al., 2022; Sindermann et al., 2020). For instance, individuals with higher levels of analytical reasoning have been found to better discriminate real from fake stimuli (Pehlivanoglu et al., 2021; Pennycook \& Rand, 2019). Prior knowledge or beliefs about the stimulus influences one's perception of it by biasing the attention deployment towards information in line with our expectations (Britt et al., 2019), and dispositional traits, such as high levels of narcissism and low levels of openness and conscientiousness, have been associated with greater susceptibility to fake news (Piksa et al., 2022; Sindermann et al., 2020).

Beyond stimulus- and individual-related characteristics, evidence suggests that the interaction between the two, i.e., the subjective reaction associated with the experience of a given stimulus, contributes to simulation monitoring decisions. For instance, the intensity of experienced emotions have been shown to increase one's sense of presence in a simulated reality, i.e., the extent to which one feels like ``being there'', as if the movie or the VR environment was real (Makowski et al., 2017; Sanchez-Vives \& Slater, 2005), and beliefs that the stimuli were fake were found to result in emotion down-regulation (Makowski, Sperduti, et al., 2019; Sperduti et al., 2017). In line with these findings, other studies on susceptibility to fake news have also found heightened stimulus emotionality to be associated with greater belief (Bago et al., 2022; Martel et al., 2020). Additionally, other factors, such as the stimulus' perceived self-relevance (Goldstein, 2009; Sperduti et al., 2016), as well as familiarity (Begg et al., 1992), could also play a role in our processing and reaction to real as opposed to non-real material.

With the advancement of technology, AI-generated images of faces have increasingly been used to study various cognitive mechanisms and processes, such as that underlying emotion processing (Dyck et al., 2008, 2010). Notably, the ability to manipulate the degree of emotionality and salience of virtual faces, by changing its facial dimensions, make them ideal targets for simulation monitoring research (Ferstl \& McDonnell, 2018; Fuentes-Hurtado et al., 2018). To this effect, the attractiveness of AI-generated faces, which integrates both components of emotional intensity and saliency {[}O'Doherty et al. (2003); DeBruine et al. (2007); sobieraj2014beautiful{]}, have indeed been associated with its perceived realness. To be specific, research findings suggest that artificially created faces were judged to be less attractive as compared to real faces {[}Liefooghe et al. (2022); tsikandilakis2019beauty; Diel and Lewis (2022){]}. Interestingly, Liefooghe et al. (2022) further reports that attractiveness ratings differed significantly between participants who were told that the faces were AI-generated from those who had no prior knowledge. Whereas such studies posit that lower perceived realness of a given stimulus leads to lower ratings of attractiveness, little is known about the impacts of attractiveness on simulation monitoring.

The goal of this study is therefore to determine whether the attractiveness of artificially-generated faces affects our reality judgement of it. Based on the Embodied Reality Theory (Makowski, 2018; Makowski, Sperduti, et al., 2019), which suggests that highly salient stimuli are perceived to be more real, we hypothesize a quadratic relationship between the perceived realness and attractiveness of a given virtual stimulus, i.e., faces rated as highly attractive or unattractive will be judged to be more real. Additionally, we further postulate that inter-individual characteristics, such as personality traits and predisposed attitudes, will interact with the relationship between perceived realness and attractiveness. Moreover, given the well-established positive correlation between attractiveness and perceived trustworthiness as well as familiarity often reported in previous studies, we posit that virtual faces judged to be real will also be rated as more trustworthy and familiar (Bartosik et al., 2021; Garrido \& Prada, 2017; Liefooghe et al., 2022; Little et al., 2011).

In line with open-science standards, all the material (stimuli generation code, experiment code, raw data, analysis script with complementary figures and analyses, preregistration, etc.) is available at \href{https://github.com/RealityBending/FakeFace}{\textbf{https://github.com/RealityBending/FakeFace}}.

\hypertarget{methods}{%
\subsection{Methods}\label{methods}}

\hypertarget{procedure}{%
\subsubsection{Procedure}\label{procedure}}

109 photos of neutral-expression faces of real individuals were retrieved from the American Multiracial Face Database (AMFD, (Chen et al., 2021)). In the first part of the study, participants answered a series of personality questionnaires. This includes the \emph{Mini-IPIP6} (24 items, Sibley et al., 2011), to measure 6 ``normal'' personality traits (Extraversion, Openness, Conscientiousness, Agreeableness, Neuroticism and Honesty-Humility); the \emph{FFNI-BF} (30 items, Jauk et al., 2022) to measure 9 facets of narcissism (acclaim-seeking, distrust, entitlement, exploitativeness, indifference, lack of empathy, manipulativeness, need for admiration and thrill-seeking); the \emph{R-GPTS} (18 items, Freeman et al., 2021), to measure 2 sub-scales of paranoid thinking (persecution and reference ideation); the \emph{IUS-12} (12 items, Carleton et al., 2007), to assess beliefs about uncertainty and the future; the \emph{SIAS-6} and the \emph{SPS-6} (6 items each, Peters et al., 2012), to assess social anxiety levels as well as a 10-item scale that measures participants general attitudes towards artificial intelligence (of which 5 items were adapted from the \emph{GAAIS} (Schepman \& Rodway, 2020)).

In the second part of this study, the set of facial images retrieved from the AMFD were presented to the participants for 500ms each, in a randomized order. Following each facial display, participants were asked to rate each face on its \textbf{Attractiveness} (``I find this person attractive''), \textbf{Beauty} (``This face is good-looking''), \textbf{Trustworthiness} (``I find this person trustworthy'') and \textbf{Familiarity} (``This person reminds me of someone I know'') using a visual analog scale.

In the last part of the study, participants were informed that half of the facial images previously seen were AI-generated. The same set of facial images displayed before were then presented for a second set of trials in a new randomized order. As per the first set, each facial stimuli was presented for 500ms. After each display, participants were asked to judge whether they thought the face they saw was real (or fake) using a visual analog scale.

This experiment was implemented using \emph{jsPsych} (De Leeuw, 2015), and the full set of instructions is available in the experiment code.

\hypertarget{participants}{%
\subsubsection{Participants}\label{participants}}

103 participants were recruited via \emph{Prolific} (\url{www.prolificacademic.co.uk}), a crowd-sourcing platform providing high data quality (Peer et al., 2022). The only inclusion criterion was a fluent proficiency in English to ensure that the experiment instructions would be well-understood. Participants were incentivised with a reward of about \textsterling 7.5 for completing the study, which took about 50 minutes to finish. Demographic variables (age, gender, and ethnicity) were self-reported on a voluntary basis.

Upon inspection of stimuli ratings, attention check responses and total duration spent to complete the personality questionnaires, 3 participants were removed for spending an implausibly short time to finish the questionnaires and having very low correlations between their stimuli ratings and that of the normative distribution.

The final sample included 100 participants (Mean age = 27.9, SD = 8.5, range: {[}19, 66{]}; Sex: 48\% females, 52\% males).

\hypertarget{data-analysis}{%
\subsubsection{Data Analysis}\label{data-analysis}}

The real-fake ratings (measured originally on a {[}-1, 1{]} analog scale) were converted into two scores, corresponding to two distinct mechanisms: the dichotomous \emph{belief} (real or fake, derived based on the sign of the rating) and the \emph{confidence} (the rating's absolute value) associated with that belief. Models predicting the former were set as logistic mixed models (with the participants and images entered as random factors), and models modeling the latter, as well as the other face ratings (attractiveness, beauty, trustworthiness and familiarity) were modeled using beta regression models (suited for an outcome variable expressed in percentages).

We started by investigating the effect of the procedure and instructions to check whether the stimuli (which were real pictures of faces) were indeed judged as fake in a sufficient proportion to warrant their analysis. Additionally, we assessed the effect of the re-exposure delay, i.e., the time between the first presentation of the image (corresponding to the face ratings) and the second presentation (for the real-fake rating).

The determinants of reality beliefs were modeled separately for attractiveness, beauty, trustworthiness, and familiarity, using second order raw polynomials coefficients to allow for possible quadratic relationships (\textbf{Figure 2}. Aside from attractiveness (conceptualized as a general construct), models for beauty, trustworthiness and familiarity were adjusted for the the two remaining variables \emph{mutatis mutandis}. We took into account the gender of participants and stimuli by retaining the pictures that were aligned with the participants' sexual preference (e.g., female faces for homosexual females, male faces for heterosexual females, and both for bisexual participants), and modeling the interaction with the participants' gender. For the attractiveness and beauty models, we then added the interaction with the reported self-attractiveness (the average of the two questions pertaining to it) to investigate its potential modulatory effect.

\begin{figure}
\includegraphics[width=1\linewidth]{../figures/Figure2} \caption{Top part shows blabla.}\label{fig:unnamed-chunk-3}
\end{figure}

Finally, we investigated the inter-individual correlates of simulation monitoring by computing, for each participant, the proportion of faces judged as real (i.e., the overall bias towards one or the other belief), as well as the average confidence for faces judged as real, and fake. We assessed the link between these scores and dispositional traits using Bayesian correlation analysis (Makowski, Ben-Shachar, Chen, et al., 2019@; Makowski et al., 2020).

The analysis was carried out using \emph{R 4.2} (R Core Team, 2022), the \emph{tidyverse} (Wickham et al., 2019), and the \emph{easystats} collection of packages (Lüdecke et al., 2021, 2019, 2020; Makowski, Ben-Shachar, \& Lüdecke, 2019). As all the details, scripts and complimentary analyses are available in open-access, the manuscript will focus on significant results.

\hypertarget{results}{%
\subsection{Results}\label{results}}

\hypertarget{manipulation-check}{%
\subsubsection{Manipulation Check}\label{manipulation-check}}

Only one image file yielded a strong simulation monitoring bias (\textgreater{} 85\%), being classified as fake in 87.4\% of trials. This image was removed from further analysis, leaving 108 trials per participant. On average, across participants, 44\% of images (95\% CI {[}0.11, 0.64{]}) were judged as fake and 56\% of images (95\% CI {[}0.36, 0.89{]}) as real. An intercept-only model with the participants and images as random factors showed that the Intraclass Correlation Coefficient (ICC), which can be interpreted as the proportion of variance explained by the random factors, was of 10.5\% for the participants and 8.7\% for the pictures.

There was a significant negative effect of the delay of re-exposure (with 95\% of values between 1.58 and 30.31 min), suggesting that shorter delays were associated with a slight bias towards the belief of reality (60\% at a theoretical delay of 0), which decreased to 50\% at a theoretical delay of 60 min (\(OR = 0.99\), \(95\% CI = [0.99, 1.00]\), \(z = -2.27\), \(p = .023\)). There was also a significant negative effect on judgment confidence, but only in the real condition (\(\beta = -0.005\), \(95\% CI = [-0.1, 0.0]\), \(p = .023\)).

\hypertarget{determinants-of-simulation-monitoring}{%
\subsubsection{Determinants of Simulation Monitoring}\label{determinants-of-simulation-monitoring}}

Attractiveness had a significant positive and linear relationship (\(R^2_{marginal}\) = 2.8\%) with the belief that a stimulus was real (\(\beta_{poly1} = 16.37\), \(95\% CI = [7.76, 24.98]\), \(z = 3.73\), \(p < .001\)) for males, and a quadratic relationship for females (\(\beta_{poly2} = 7.77\), \(95\% CI = [1.41, 14.13]\), \(z = 2.40\), \(p = .017\)), with both non-attractive and attractive faces being judged as more real. No significant relationship was found between attractiveness ratings and belief confidence, aside of a similar trend for females only, for faces judged as real (\(\beta_{poly2} = 4.38\), \(95\% CI = [0.96, 7.79]\), \(z = 2.51\), \(p = .012\)). There was no interaction with reported self-attractiveness.

Beauty, adjusted for trustworthiness and familiarity, had a significant positive and linear relationship (\(R^2_{marginal}\) = 3.5\%) with the belief that a stimulus was real (\(\beta_{poly1} = 9.54\), \(95\% CI = [1.43, 17.65]\), \(z = 2.31\), \(p = .021\)) for males only. No effect on confidence was found, aside from a quadratic relationship for females for faces judged as fake, suggesting that non-beautiful and highly beautiful faces were rated as fake with more confidence than average faces (\(\beta_{poly2} = 6.61\), \(95\% CI = [1.98, 11.24]\), \(z = 2.80\), \(p = .005\)). There was no interaction with reported self-attractiveness.

Trustworthiness, adjusted for beauty and familiarity, had a significant positive and linear relationship (\(R^2_{marginal}\) = 3.0\%) with the belief that a stimulus was real (\(\beta_{poly1} = 11.60\), \(95\% CI = [4.15, 19.06]\), \(z = 3.05\), \(p = .002\)) for females only. No effect on confidence was found, aside from a quadratic relationship for females for faces judged as real, suggesting that non-trustworthy and highly trustworthy faces were rated as real with more confidence than average faces (\(\beta_{poly2} = 6.47\), \(95\% CI = [1.73, 11.21]\), \(z = 2.68\), \(p = .007\)).

We did not find any significant relationships for familiarity adjusted for beauty and trustworthiness (\(R^2_{marginal}\) = 3.0\%). However, a significant positive and linear relationship was found with the confidence in faces judged as real (\(\beta_{poly1} = 9.31\), \(95\% CI = [3.45, 15.17]\), \(z = -3.11\), \(p = .002\)), and a quadratic relationship for faces judged as fake (\(\beta_{poly1} = -12.67\), \(95\% CI = [-19.87, -5.47]\), \(z = -3.45\), \(p < .001\); \(\beta_{poly2} = 8.14\), \(95\% CI = [0.01, 16.28]\), \(z = 1.96\), \(p = .05\)), for males only, suggesting that faces judged as real with more confidence when they are familiar, and judged as fake with less confidence when they are of not familiar or highly familiar.

\hypertarget{inter-individual-correlates-of-simulation-monitoring}{%
\subsubsection{Inter-Individual Correlates of Simulation Monitoring}\label{inter-individual-correlates-of-simulation-monitoring}}

Bayesian correlations with personality traits suggested that Honesty-Humility was negatively associated with the confidence in reality (\(r = -0.21\), \(95\% CI = [-0.38, -0.03]\), \(BF_{10} = 3.57\)), and positively associated with the Narcissism trait of Acclaim Seeking (\(r = 0.26\), \(95\% CI = [0.08, 0.43]\), \(BF_{10} = 14.38\)) and Grandiose Fantasies (\(r = 0.22\), \(95\% CI = [0.04, 0.40]\), \(BF_{10} = 4.18\)). Acclaim Seeking was also positively related with the confidence in fake judgments (\(r = 0.22\), \(95\% CI = [0.04, 0.40]\), \(BF_{10} = 4.52\)). No significant correlations was found for social anxiety, intolerance to uncertainty, or paranoid beliefs.

Questions pertaining to the attitude towards AI were reduced to 3 dimensions through factor analysis, labelled AI-Enthusiasm (loaded by items expressing interest and excitement in AI development and applications), AI-Realness (loaded by items expressing positive opinions on the ability of AI to create realistic material), and AI-Danger (loaded by items expressing concerns on the unethical misuse of AI technology). Only AI-Enthusiasm displayed a significant positive relationship with the confidence in both real (\(r = 0.24\), \(95\% CI = [0.06, 0.41]\), \(BF_{10} = 8.00\)) and fake (\(r = 0.28\), \(95\% CI = [0.11, 0.44]\), \(BF_{10} = 23.04\)) judgments.

\hypertarget{discussion}{%
\subsection{Discussion}\label{discussion}}

Although expected, the first striking result is that despite all items being real photos from the same database, all people easily believe (to high degrees of confidence) that a significant proportion of them was fake. This is a testimony to the existing expectations regarding CGI technology, as much as to the volatility of our sense of reality. In fact, stimuli-related and participant-related characteristics accounted for about only less than 20\% of the variance in the beliefs, suggesting that a large part of it is related to other subjective processes.

Though attractiveness does not seem to be the primary drive underlying simulation monitoring of face images, it does nonetheless display an association.

\hypertarget{acknowledgments}{%
\section{Acknowledgments}\label{acknowledgments}}

We would like to thank STUDENT NAME for his contribution.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-bago2022emotion}{}}%
Bago, B., Rosenzweig, L. R., Berinsky, A. J., \& Rand, D. G. (2022). Emotion may predict susceptibility to fake news but emotion regulation does not seem to help. \emph{Cognition and Emotion}, 1--15.

\leavevmode\vadjust pre{\hypertarget{ref-bartosik2021you}{}}%
Bartosik, B., Wojcik, G. M., Brzezicka, A., \& Kawiak, A. (2021). Are you able to trust me? Analysis of the relationships between personality traits and the assessment of attractiveness and trust. \emph{Frontiers in Human Neuroscience}, \emph{15}, 685530.

\leavevmode\vadjust pre{\hypertarget{ref-begg1992dissociation}{}}%
Begg, I. M., Anas, A., \& Farinacci, S. (1992). Dissociation of processes in belief: Source recollection, statement familiarity, and the illusion of truth. \emph{Journal of Experimental Psychology: General}, \emph{121}(4), 446.

\leavevmode\vadjust pre{\hypertarget{ref-britt2019reasoned}{}}%
Britt, M. A., Rouet, J.-F., Blaum, D., \& Millis, K. (2019). A reasoned approach to dealing with fake news. \emph{Policy Insights from the Behavioral and Brain Sciences}, \emph{6}(1), 94--101.

\leavevmode\vadjust pre{\hypertarget{ref-bryanov2021determinants}{}}%
Bryanov, K., \& Vziatysheva, V. (2021). Determinants of individuals' belief in fake news: A scoping review determinants of belief in fake news. \emph{PLoS One}, \emph{16}(6), e0253717.

\leavevmode\vadjust pre{\hypertarget{ref-carleton2007fearing}{}}%
Carleton, R. N., Norton, M. P. J., \& Asmundson, G. J. (2007). Fearing the unknown: A short version of the intolerance of uncertainty scale. \emph{Journal of Anxiety Disorders}, \emph{21}(1), 105--117.

\leavevmode\vadjust pre{\hypertarget{ref-chen2021broadening}{}}%
Chen, J. M., Norman, J. B., \& Nam, Y. (2021). Broadening the stimulus set: Introducing the american multiracial faces database. \emph{Behavior Research Methods}, \emph{53}(1), 371--389.

\leavevmode\vadjust pre{\hypertarget{ref-de2015jspsych}{}}%
De Leeuw, J. R. (2015). jsPsych: A JavaScript library for creating behavioral experiments in a web browser. \emph{Behavior Research Methods}, \emph{47}(1), 1--12.

\leavevmode\vadjust pre{\hypertarget{ref-debruine2007dissociating}{}}%
DeBruine, L. M., Jones, B. C., Unger, L., Little, A. C., \& Feinberg, D. R. (2007). Dissociating averageness and attractiveness: Attractive faces are not always average. \emph{Journal of Experimental Psychology: Human Perception and Performance}, \emph{33}(6), 1420.

\leavevmode\vadjust pre{\hypertarget{ref-diel2022familiarity}{}}%
Diel, A., \& Lewis, M. (2022). Familiarity, orientation, and realism increase face uncanniness by sensitizing to facial distortions. \emph{Journal of Vision}, \emph{22}(4), 14--14.

\leavevmode\vadjust pre{\hypertarget{ref-dyck2008recognition}{}}%
Dyck, M., Winbeck, M., Leiberg, S., Chen, Y., Gur, R. C., \& Mathiak, K. (2008). Recognition profile of emotions in natural and virtual faces. \emph{PloS One}, \emph{3}(11), e3628.

\leavevmode\vadjust pre{\hypertarget{ref-dyck2010virtual}{}}%
Dyck, M., Winbeck, M., Leiberg, S., Chen, Y., \& Mathiak, K. (2010). Virtual faces as a tool to study emotion recognition deficits in schizophrenia. \emph{Psychiatry Research}, \emph{179}(3), 247--252.

\leavevmode\vadjust pre{\hypertarget{ref-ecker2022psychological}{}}%
Ecker, U. K., Lewandowsky, S., Cook, J., Schmid, P., Fazio, L. K., Brashier, N., Kendeou, P., Vraga, E. K., \& Amazeen, M. A. (2022). The psychological drivers of misinformation belief and its resistance to correction. \emph{Nature Reviews Psychology}, \emph{1}(1), 13--29.

\leavevmode\vadjust pre{\hypertarget{ref-ferstl2018perceptual}{}}%
Ferstl, Y., \& McDonnell, R. (2018). A perceptual study on the manipulation of facial features for trait portrayal in virtual agents. \emph{Proceedings of the 18th International Conference on Intelligent Virtual Agents}, 281--288.

\leavevmode\vadjust pre{\hypertarget{ref-freeman2021revised}{}}%
Freeman, D., Loe, B. S., Kingdon, D., Startup, H., Molodynski, A., Rosebrock, L., Brown, P., Sheaves, B., Waite, F., \& Bird, J. C. (2021). The revised green et al., Paranoid thoughts scale (r-GPTS): Psychometric properties, severity ranges, and clinical cut-offs. \emph{Psychological Medicine}, \emph{51}(2), 244--253.

\leavevmode\vadjust pre{\hypertarget{ref-fuentes2018evolutionary}{}}%
Fuentes-Hurtado, F., Diego-Mas, J. A., Naranjo, V., \& Alcañiz, M. (2018). Evolutionary computation for modelling social traits in realistic looking synthetic faces. \emph{Complexity}, \emph{2018}.

\leavevmode\vadjust pre{\hypertarget{ref-garrido2017kdef}{}}%
Garrido, M. V., \& Prada, M. (2017). KDEF-PT: Valence, emotional intensity, familiarity and attractiveness ratings of angry, neutral, and happy faces. \emph{Frontiers in Psychology}, \emph{8}, 2181.

\leavevmode\vadjust pre{\hypertarget{ref-goldstein2009pleasure}{}}%
Goldstein, T. R. (2009). The pleasure of unadulterated sadness: Experiencing sorrow in fiction, nonfiction, and" in person.". \emph{Psychology of Aesthetics, Creativity, and the Arts}, \emph{3}(4), 232.

\leavevmode\vadjust pre{\hypertarget{ref-jauk2022validation}{}}%
Jauk, E., Olaru, G., Schürch, E., Back, M. D., \& Morf, C. C. (2022). Validation of the german five-factor narcissism inventory and construction of a brief form using ant colony optimization. \emph{Assessment}, 10731911221075761.

\leavevmode\vadjust pre{\hypertarget{ref-lewandowsky2017beyond}{}}%
Lewandowsky, S., Ecker, U. K., \& Cook, J. (2017). Beyond misinformation: Understanding and coping with the {``post-truth''} era. \emph{Journal of Applied Research in Memory and Cognition}, \emph{6}(4), 353--369.

\leavevmode\vadjust pre{\hypertarget{ref-liefooghe2022faces}{}}%
Liefooghe, B., Oliveira, M., Leisten, L. M., Hoogers, E., Aarts, H., \& Hortensius, R. (2022). \emph{Faces merely labelled as artificial are trusted less}.

\leavevmode\vadjust pre{\hypertarget{ref-little2011facial}{}}%
Little, A. C., Jones, B. C., \& DeBruine, L. M. (2011). Facial attractiveness: Evolutionary based research. \emph{Philosophical Transactions of the Royal Society B: Biological Sciences}, \emph{366}(1571), 1638--1659.

\leavevmode\vadjust pre{\hypertarget{ref-parametersArticle}{}}%
Lüdecke, D., Ben-Shachar, M., Patil, I., \& Makowski, D. (2020). Extracting, computing and exploring the parameters of statistical models using {R}. \emph{Journal of Open Source Software}, \emph{5}(53), 2445. \url{https://doi.org/10.21105/joss.02445}

\leavevmode\vadjust pre{\hypertarget{ref-performanceArticle}{}}%
Lüdecke, D., Ben-Shachar, M., Patil, I., Waggoner, P., \& Makowski, D. (2021). {performance}: An {R} package for assessment, comparison and testing of statistical models. \emph{Journal of Open Source Software}, \emph{6}(60), 3139. \url{https://doi.org/10.21105/joss.03139}

\leavevmode\vadjust pre{\hypertarget{ref-insightArticle}{}}%
Lüdecke, D., Waggoner, P., \& Makowski, D. (2019). Insight: A unified interface to access information from model objects in {R}. \emph{Journal of Open Source Software}, \emph{4}(38), 1412. \url{https://doi.org/10.21105/joss.01412}

\leavevmode\vadjust pre{\hypertarget{ref-makowski2018cognitive}{}}%
Makowski, D. (2018). \emph{Cognitive neuropsychology of implicit emotion regulation through fictional reappraisal} {[}PhD thesis{]}. Sorbonne Paris Cit{é}.

\leavevmode\vadjust pre{\hypertarget{ref-makowski2019indices}{}}%
Makowski, D., Ben-Shachar, M. S., Chen, S. A., \& Lüdecke, D. (2019). Indices of effect existence and significance in the bayesian framework. \emph{Frontiers in Psychology}, \emph{10}, 2767.

\leavevmode\vadjust pre{\hypertarget{ref-bayestestRArticle}{}}%
Makowski, D., Ben-Shachar, M., \& Lüdecke, D. (2019). {bayestestR}: Describing effects and their uncertainty, existence and significance within the {Bayesian} framework. \emph{Journal of Open Source Software}, \emph{4}(40), 1541. \url{https://doi.org/10.21105/joss.01541}

\leavevmode\vadjust pre{\hypertarget{ref-correlationArticle}{}}%
Makowski, D., Ben-Shachar, M., Patil, I., \& Lüdecke, D. (2020). Methods and algorithms for correlation analysis in {R}. \emph{Journal of Open Source Software}, \emph{5}(51), 2306. \url{https://doi.org/10.21105/joss.02306}

\leavevmode\vadjust pre{\hypertarget{ref-makowski2017being}{}}%
Makowski, D., Sperduti, M., Nicolas, S., \& Piolino, P. (2017). {``Being there''} and remembering it: Presence improves memory encoding. \emph{Consciousness and Cognition}, \emph{53}, 194--202.

\leavevmode\vadjust pre{\hypertarget{ref-makowski2019phenomenal}{}}%
Makowski, D., Sperduti, M., Pelletier, J., Blondé, P., La Corte, V., Arcangeli, M., Zalla, T., Lemaire, S., Dokic, J., Nicolas, S., et al. (2019). Phenomenal, bodily and brain correlates of fictional reappraisal as an implicit emotion regulation strategy. \emph{Cognitive, Affective, \& Behavioral Neuroscience}, \emph{19}(4), 877--897.

\leavevmode\vadjust pre{\hypertarget{ref-martel2020reliance}{}}%
Martel, C., Pennycook, G., \& Rand, D. G. (2020). Reliance on emotion promotes belief in fake news. \emph{Cognitive Research: Principles and Implications}, \emph{5}(1), 1--20.

\leavevmode\vadjust pre{\hypertarget{ref-mcdonnell2010face}{}}%
McDonnell, R., \& Breidt, M. (2010). Face reality: Investigating the uncanny valley for virtual faces. In \emph{ACM SIGGRAPH ASIA 2010 sketches} (pp. 1--2).

\leavevmode\vadjust pre{\hypertarget{ref-michael2021source}{}}%
Michael, R. B., \& Sanson, M. (2021). Source information affects interpretations of the news across multiple age groups in the united states. \emph{Societies}, \emph{11}(4), 119.

\leavevmode\vadjust pre{\hypertarget{ref-moshel2022}{}}%
Moshel, M. L., Robinson, A. K., Carlson, T. A., \& Grootswagers, T. (2022). Are you for real? Decoding realistic AI-generated faces from neural activity. \emph{Vision Research}, \emph{199}, 108079. \url{https://doi.org/10.1016/j.visres.2022.108079}

\leavevmode\vadjust pre{\hypertarget{ref-nightingale2022}{}}%
Nightingale, S. J., \& Farid, H. (2022). AI-synthesized faces are indistinguishable from real faces and more trustworthy. \emph{Proceedings of the National Academy of Sciences}, \emph{119}(8), e2120481119. \url{https://doi.org/10.1073/pnas.2120481119}

\leavevmode\vadjust pre{\hypertarget{ref-o2003beauty}{}}%
O'Doherty, J., Winston, J., Critchley, H., Perrett, D., Burt, D. M., \& Dolan, R. J. (2003). Beauty in a smile: The role of medial orbitofrontal cortex in facial attractiveness. \emph{Neuropsychologia}, \emph{41}(2), 147--155.

\leavevmode\vadjust pre{\hypertarget{ref-pantserev2020}{}}%
Pantserev, K. (2020). \emph{The malicious use of AI-based deepfake technology as the new threat to psychological security and political stability} (pp. 37--55). \url{https://doi.org/10.1007/978-3-030-35746-7_3}

\leavevmode\vadjust pre{\hypertarget{ref-peer2022}{}}%
Peer, E., Rothschild, D., Gordon, A., Evernden, Z., \& Damer, E. (2022). Data quality of platforms and panels for online behavioral research. \emph{Behavior Research Methods}, \emph{54}(4), 1643--1662. \url{https://doi.org/10.3758/s13428-021-01694-3}

\leavevmode\vadjust pre{\hypertarget{ref-pehlivanoglu2021role}{}}%
Pehlivanoglu, D., Lin, T., Deceus, F., Heemskerk, A., Ebner, N. C., \& Cahill, B. S. (2021). The role of analytical reasoning and source credibility on the evaluation of real and fake full-length news articles. \emph{Cognitive Research: Principles and Implications}, \emph{6}(1), 1--12.

\leavevmode\vadjust pre{\hypertarget{ref-pennycook2019lazy}{}}%
Pennycook, G., \& Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. \emph{Cognition}, \emph{188}, 39--50.

\leavevmode\vadjust pre{\hypertarget{ref-peters2012development}{}}%
Peters, L., Sunderland, M., Andrews, G., Rapee, R. M., \& Mattick, R. P. (2012). Development of a short form social interaction anxiety (SIAS) and social phobia scale (SPS) using nonparametric item response theory: The SIAS-6 and the SPS-6. \emph{Psychological Assessment}, \emph{24}(1), 66.

\leavevmode\vadjust pre{\hypertarget{ref-piksa2022cognitive}{}}%
Piksa, M., Noworyta, K., Piasecki, J., Gwiazdzinski, P., Gundersen, A. B., Kunst, J., \& Rygula, R. (2022). Cognitive processes and personality traits underlying four phenotypes of susceptibility to (mis) information. \emph{Frontiers in Psychiatry}, 1142.

\leavevmode\vadjust pre{\hypertarget{ref-RCoreTeam2022}{}}%
R Core Team. (2022). \emph{R: A language and environment for statistical computing}. R Foundation for Statistical Computing. \url{https://www.R-project.org/}

\leavevmode\vadjust pre{\hypertarget{ref-sanchez2005presence}{}}%
Sanchez-Vives, M. V., \& Slater, M. (2005). From presence to consciousness through virtual reality. \emph{Nature Reviews Neuroscience}, \emph{6}(4), 332--339.

\leavevmode\vadjust pre{\hypertarget{ref-schepman2020initial}{}}%
Schepman, A., \& Rodway, P. (2020). Initial validation of the general attitudes towards artificial intelligence scale. \emph{Computers in Human Behavior Reports}, \emph{1}, 100014.

\leavevmode\vadjust pre{\hypertarget{ref-sibley2011}{}}%
Sibley, C., Luyten, N., Wolfman, M., Mobberley, A., Wootton, L. W., Hammond, M., Sengupta, N., Perry, R., West-Newman, T., Wilson, M., McLellan, L., Hoverd, W. J., \& Robertson, A. (2011). The mini-IPIP6: Validation and extension of a short measure of the big-six factors of personality in new zealand. \emph{New Zealand Journal of Psychology}, \emph{40}, 142--159.

\leavevmode\vadjust pre{\hypertarget{ref-sindermann2020short}{}}%
Sindermann, C., Cooper, A., \& Montag, C. (2020). A short review on susceptibility to falling for fake political news. \emph{Current Opinion in Psychology}, \emph{36}, 44--48.

\leavevmode\vadjust pre{\hypertarget{ref-sperduti2016paradox}{}}%
Sperduti, M., Arcangeli, M., Makowski, D., Wantzen, P., Zalla, T., Lemaire, S., Dokic, J., Pelletier, J., \& Piolino, P. (2016). The paradox of fiction: Emotional response toward fiction and the modulatory role of self-relevance. \emph{Acta Psychologica}, \emph{165}, 53--59.

\leavevmode\vadjust pre{\hypertarget{ref-sperduti2017distinctive}{}}%
Sperduti, M., Makowski, D., Arcangeli, M., Wantzen, P., Zalla, T., Lemaire, S., Dokic, J., Pelletier, J., \& Piolino, P. (2017). The distinctive role of executive functions in implicit emotion regulation. \emph{Acta Psychologica}, \emph{173}, 13--20.

\leavevmode\vadjust pre{\hypertarget{ref-susmann2021persuasion}{}}%
Susmann, M. W., Xu, M., Clark, J. K., Wallace, L. E., Blankenship, K. L., Philipp-Muller, A. Z., Luttrell, A., Wegener, D. T., \& Petty, R. E. (2021). Persuasion amidst a pandemic: Insights from the elaboration likelihood model. \emph{European Review of Social Psychology}, 1--37.

\leavevmode\vadjust pre{\hypertarget{ref-tucciarelli2020}{}}%
Tucciarelli, R., Vehar, N., \& Tsakiris, M. (2020). \emph{On the realness of people who do not exist: the social processing of artificial faces}. \url{https://doi.org/10.31234/osf.io/dnk9x}

\leavevmode\vadjust pre{\hypertarget{ref-wickham2019}{}}%
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., \ldots{} Yutani, H. (2019). Welcome to the {tidyverse}. \emph{Journal of Open Source Software}, \emph{4}(43), 1686. \url{https://doi.org/10.21105/joss.01686}

\end{CSLReferences}


\clearpage
\renewcommand{\listfigurename}{Figure captions}


\end{document}
